import os

import numpy as np

import cv2

from sklearn.cluster import KMeans

from sklearn.preprocessing import StandardScaler

from sklearn.decomposition import PCA

import matplotlib.pyplot as plt

from sklearn.metrics import silhouette_score

from sklearn.metrics import classification_report

from sklearn.preprocessing import LabelEncoder

from sklearn.metrics import accuracy_score


def load_images_from_folder(folder, size=(128, 128)):

images = []

for filename in os.listdir(folder):

img_path = os.path.join(folder, filename)

img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE) # Load image in grayscale

if img is not None:

img_resized = cv2.resize(img, size) # Resize image

images.append(img_resized)

return images


def extract_features(images):

features = []

for img in images:

# Flatten the image and normalize pixel values to be between 0 and 1

img_flatten = img.flatten() / 255.0

features.append(img_flatten)

return np.array(features)


def preprocess_image(image_path, size=(128, 128)):

img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE) # Load image in grayscale

if img is None:

raise ValueError(f"Image at {image_path} could not be loaded.")

img_resized = cv2.resize(img, size) # Resize image

img_flatten = img_resized.flatten() / 255.0 # Flatten and normalize pixel values

return np.expand_dims(img_flatten, axis=0) # Add batch dimension


# Directories

train_dir = 'Downloads/Training Oral Cancer Dataset'

test_dir = 'Downloads/Testing Oral Cancer Dataset'


# Load images and extract features

train_cancer_imgs = load_images_from_folder(os.path.join(train_dir, 'CANCER'))

train_non_cancer_imgs = load_images_from_folder(os.path.join(train_dir, 'NON CANCER'))

test_cancer_imgs = load_images_from_folder(os.path.join(test_dir, 'CANCER'))

test_non_cancer_imgs = load_images_from_folder(os.path.join(test_dir, 'NON CANCER'))


# Extract features

train_cancer_features = extract_features(train_cancer_imgs)

train_non_cancer_features = extract_features(train_non_cancer_imgs)

test_cancer_features = extract_features(test_cancer_imgs)

test_non_cancer_features = extract_features(test_non_cancer_imgs)


# Combine and create labels

X_train = np.vstack([train_cancer_features, train_non_cancer_features])

y_train = np.array([1] * len(train_cancer_features) + [0] * len(train_non_cancer_features))
X_test = np.vstack([test_cancer_features, test_non_cancer_features])

y_test = np.array([1] * len(test_cancer_features) + [0] * len(test_non_cancer_features))


# Standardize features

scaler = StandardScaler()

X_train_scaled = scaler.fit_transform(X_train)

X_test_scaled = scaler.transform(X_test)


# Dimensionality Reduction

pca = PCA(n_components=2)

X_train_pca = pca.fit_transform(X_train_scaled)

X_test_pca = pca.transform(X_test_scaled)


# Determine the number of clusters (for K-means)

n_clusters = 2 # Since we have cancer and non-cancer classes


joblib.dump(kmeans, 'kmeans_model.pkl')

joblib.dump(scaler, 'scaler.pkl')

joblib.dump(pca, 'pca.pkl')


# Initialize and fit K-means

kmeans = KMeans(n_clusters=n_clusters, random_state=42)

kmeans.fit(X_train_scaled)

# Predict cluster labels

train_labels = kmeans.predict(X_train_scaled)

test_labels = kmeans.predict(X_test_scaled)


# Compute silhouette score

sil_score = silhouette_score(X_train_scaled, train_labels)
print(f'Silhouette Score: {sil_score:.2f}')


# Plot the results (for PCA-reduced data)

plt.figure(figsize=(12, 6))


plt.subplot(1, 2, 1)

plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=train_labels, cmap='viridis', marker='o', edgecolor='k')

plt.title('Training Data Clustering')

plt.xlabel('Principal Component 1')

plt.ylabel('Principal Component 2')


plt.subplot(1, 2, 2)

plt.scatter(X_test_pca[:, 0], X_test_pca[:, 1], c=test_labels, cmap='viridis', marker='o', edgecolor='k')

plt.title('Test Data Clustering')

plt.xlabel('Principal Component 1')

plt.ylabel('Principal Component 2')


plt.colorbar(label='Cluster Label')

plt.show()


# Optional: Evaluate the clustering

# Since this is an unsupervised learning task, evaluating clustering accuracy is non-trivial

# Here we use the true labels to compute accuracy for demonstration purposes

print("Training Accuracy:")

print(accuracy_score(y_train, train_labels))

print("Test Accuracy:")

print(accuracy_score(y_test, test_labels))

import joblib

from sklearn.cluster import KMeans

from sklearn.preprocessing import StandardScaler

from sklearn.decomposition import PCA


new_image_path='Downloads/Testing Oral Cancer Dataset/NON CANCER/250.jpeg'


def preprocess_image(image_path, size=(128, 128)):

img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE) # Load image in grayscale

if img is None:

raise ValueError(f"Image at {image_path} could not be loaded.")

img_resized = cv2.resize(img, size) # Resize image

img_flatten = img_resized.flatten() / 255.0 # Flatten and normalize pixel values

return np.expand_dims(img_flatten, axis=0) # Add batch dimension


# Load the model components

kmeans = joblib.load('kmeans_model.pkl')

scaler = joblib.load('scaler.pkl')

pca = joblib.load('pca.pkl')


# Process the new image

new_image_features = preprocess_image(new_image_path)

new_image_scaled = scaler.transform(new_image_features)

new_image_pca = pca.transform(new_image_scaled)

predicted_cluster = kmeans.predict(new_image_scaled)


# Print the prediction result

print(f"Predicted cluster for the new image: {predicted_cluster[0]}")

if predicted_cluster[0]==0:

print("CANCER");
else:

print("NON CANCER");


# Display the image

img = cv2.imread(new_image_path)

if img is not None:

plt.figure(figsize=(6, 6))

plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)) # Convert BGR to RGB

plt.title(f"Predicted Cluster: {predicted_cluster[0]}")

plt.axis('off')

plt.show()

else:

print("Error displaying the image.")


from collections import Counter


# Count the number of samples in each cluster for training data

cluster_labels_train = kmeans.predict(X_train_scaled)

cluster_counts = Counter(cluster_labels_train)


# Print out how many samples of each class are in each cluster

for cluster in range(n_clusters):

cluster_indices = np.where(cluster_labels_train == cluster)[0]

cluster_labels = y_train[cluster_indices]

print(f"Cluster {cluster} contains {Counter(cluster_labels)}")